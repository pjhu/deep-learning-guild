{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification And Regression Trees 回归树\n",
    "# https://blog.csdn.net/jiaoyangwm/article/details/79525237\n",
    "\n",
    "# https://github.com/apachecn/AiLearning/blob/master/docs/ml/9.%E6%A0%91%E5%9B%9E%E5%BD%92.md\n",
    "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree\n",
    "\n",
    "import numpy as np\n",
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年龄：0代表青年，1代表中年，2代表老年；\n",
    "# 有工作：0代表否，1代表是；\n",
    "# 有自己的房子：0代表否，1代表是；\n",
    "# 信贷情况：0代表一般，1代表好，2代表非常好；\n",
    "# 类别(是否给贷款)：no代表否，yes代表是。\n",
    "# labels=['年龄','有工作','有自己的房子','信贷情况']\n",
    "dataSet = [[0, 0, 0, 0, 0],\n",
    "           [0, 0, 0, 1, 0],\n",
    "           [0, 1, 0, 1, 1],\n",
    "           [0, 1, 1, 0, 1],\n",
    "           [0, 0, 0, 0, 0],\n",
    "           [1, 0, 0, 0, 0],\n",
    "           [1, 0, 0, 1, 0],\n",
    "           [1, 1, 1, 1, 1],\n",
    "           [1, 0, 1, 2, 1],\n",
    "           [1, 0, 1, 2, 1],\n",
    "           [2, 0, 1, 2, 1],\n",
    "           [2, 0, 1, 1, 1],\n",
    "           [2, 1, 0, 1, 1],\n",
    "           [2, 1, 0, 2, 1],\n",
    "           [2, 0, 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6, 1: 9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 信息熵(information entropy)\n",
    "def calcShannonEnt(dataSet):\n",
    "    #返回数据集行数\n",
    "    numEntries=len(dataSet)\n",
    "    #保存每个标签（label）出现次数的字典\n",
    "    labelCounts={}\n",
    "    #对每组特征向量进行统计\n",
    "    for featVec in dataSet:\n",
    "        currentLabel=featVec[-1]                     #提取标签信息\n",
    "        if currentLabel not in labelCounts.keys():   #如果标签没有放入统计次数的字典，添加进去\n",
    "            labelCounts[currentLabel]=0\n",
    "        labelCounts[currentLabel]+=1                 #label计数\n",
    "    print(labelCounts)\n",
    "    shannonEnt=0.0\n",
    "    #计算信息熵\n",
    "    for key in labelCounts:\n",
    "        prob=float(labelCounts[key])/numEntries      #选择该标签的概率\n",
    "        shannonEnt-=prob*log(prob,2)                 #利用公式计算\n",
    "    return shannonEnt\n",
    "\n",
    "calcShannonEnt(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6, 1: 9}\n",
      "{0: 3, 1: 2}\n",
      "{0: 2, 1: 3}\n",
      "{1: 4, 0: 1}\n",
      "第0个特征的增益为0.083\n",
      "{0: 6, 1: 4}\n",
      "{1: 5}\n",
      "第1个特征的增益为0.324\n",
      "{0: 6, 1: 3}\n",
      "{1: 6}\n",
      "第2个特征的增益为0.420\n",
      "{0: 4, 1: 1}\n",
      "{0: 2, 1: 4}\n",
      "{1: 4}\n",
      "第3个特征的增益为0.363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 信息增益(information gain)\n",
    "\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    #特征数量\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    #计数数据集的香农熵\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    #信息增益\n",
    "    bestInfoGain = 0.0\n",
    "    #最优特征的索引值\n",
    "    bestFeature = -1\n",
    "    #遍历所有特征\n",
    "    for i in range(numFeatures):\n",
    "        # 获取dataSet的第i个所有特征\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        #创建set集合{}，元素不可重复\n",
    "        uniqueVals = set(featList)\n",
    "        #经验条件熵\n",
    "        newEntropy = 0.0\n",
    "        #计算信息增益\n",
    "        for value in uniqueVals:\n",
    "            #subDataSet划分后的子集\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            #计算子集的概率\n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            #根据公式计算经验条件熵\n",
    "            newEntropy += prob * calcShannonEnt((subDataSet))\n",
    "        #信息增益\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        #打印每个特征的信息增益\n",
    "        print(\"第%d个特征的增益为%.3f\" % (i, infoGain))\n",
    "        #计算信息增益\n",
    "        if (infoGain > bestInfoGain):\n",
    "            #更新信息增益，找到最大的信息增益\n",
    "            bestInfoGain = infoGain\n",
    "            #记录信息增益最大的特征的索引值\n",
    "            bestFeature = i\n",
    "            #返回信息增益最大特征的索引值\n",
    "    return bestFeature\n",
    "\n",
    "\"\"\"\n",
    "Parameters：\n",
    "    dataSet：待划分的数据集\n",
    "    axis：划分数据集的特征\n",
    "    value：需要返回的特征的值\n",
    "\n",
    "\"\"\"\n",
    "def splitDataSet(dataSet,axis,value):\n",
    "    retDataSet=[]\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis]==value:\n",
    "            reducedFeatVec=featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "chooseBestFeatureToSplit(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明：统计classList中出现次数最多的元素（类标签）\n",
    "Parameters：\n",
    "    classList：类标签列表\n",
    "Returns：\n",
    "    sortedClassCount[0][0]：出现次数最多的元素（类标签）\n",
    "Modify：\n",
    "    2018-03-13\n",
    "\n",
    "\"\"\"\n",
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    #统计classList中每个元素出现的次数\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote]=0\n",
    "            classCount[vote]+=1\n",
    "        #根据字典的值降序排列\n",
    "        sortedClassCount=sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "        return sortedClassCount[0][0]\n",
    "    \n",
    "def createTree(dataSet,labels,featLabels):\n",
    "    #取分类标签（是否放贷：yes or no）\n",
    "    classList=[example[-1] for example in dataSet]\n",
    "    #如果类别完全相同，则停止继续划分\n",
    "    if classList.count(classList[0])==len(classList):\n",
    "        return classList[0]\n",
    "    #遍历完所有特征时返回出现次数最多的类标签\n",
    "    if len(dataSet[0])==1:\n",
    "        return majorityCnt(classList)\n",
    "    #选择最优特征\n",
    "    bestFeat=chooseBestFeatureToSplit(dataSet)\n",
    "    #最优特征的标签\n",
    "    bestFeatLabel=labels[bestFeat]\n",
    "    featLabels.append(bestFeatLabel)\n",
    "    #根据最优特征的标签生成树\n",
    "    myTree={bestFeatLabel:{}}\n",
    "    #删除已经使用的特征标签\n",
    "    del(labels[bestFeat])\n",
    "    #得到训练集中所有最优特征的属性值\n",
    "    featValues=[example[bestFeat] for example in dataSet]\n",
    "    #去掉重复的属性值\n",
    "    uniqueVls=set(featValues)\n",
    "    #遍历特征，创建决策树\n",
    "    for value in uniqueVls:\n",
    "        myTree[bestFeatLabel][value]=createTree(splitDataSet(dataSet,bestFeat,value),labels,featLabels)\n",
    "    return myTree\n",
    "\n",
    "def predict(inputTree,featLabels,testVec):\n",
    "    #获取决策树节点\n",
    "    firstStr=next(iter(inputTree))\n",
    "    print(firstStr)\n",
    "    #下一个字典\n",
    "    secondDict=inputTree[firstStr]\n",
    "    print(secondDict)\n",
    "    featIndex=featLabels.index(firstStr)\n",
    "    print(featIndex)\n",
    "    print('keys: ',secondDict.keys())\n",
    "\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex]==key:\n",
    "            if type(secondDict[key]).__name__=='dict':\n",
    "                classLabel=classify(secondDict[key],featLabels,testVec)\n",
    "            else: classLabel=secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6, 1: 9}\n",
      "{0: 3, 1: 2}\n",
      "{0: 2, 1: 3}\n",
      "{1: 4, 0: 1}\n",
      "第0个特征的增益为0.083\n",
      "{0: 6, 1: 4}\n",
      "{1: 5}\n",
      "第1个特征的增益为0.324\n",
      "{0: 6, 1: 3}\n",
      "{1: 6}\n",
      "第2个特征的增益为0.420\n",
      "{0: 4, 1: 1}\n",
      "{0: 2, 1: 4}\n",
      "{1: 4}\n",
      "第3个特征的增益为0.363\n",
      "{0: 6, 1: 3}\n",
      "{0: 3, 1: 1}\n",
      "{0: 2}\n",
      "{1: 2, 0: 1}\n",
      "第0个特征的增益为0.252\n",
      "{0: 6}\n",
      "{1: 3}\n",
      "第1个特征的增益为0.918\n",
      "{0: 4}\n",
      "{0: 2, 1: 2}\n",
      "{1: 1}\n",
      "第2个特征的增益为0.474\n",
      "{'有自己的房子': {0: {'有工作': {0: 0, 1: 1}}, 1: 1}}\n",
      "有自己的房子\n",
      "{0: {'有工作': {0: 0, 1: 1}}, 1: 1}\n",
      "0\n",
      "keys:  dict_keys([0, 1])\n",
      "有工作\n",
      "{0: 0, 1: 1}\n",
      "1\n",
      "keys:  dict_keys([0, 1])\n",
      "放贷\n"
     ]
    }
   ],
   "source": [
    "labels=['年龄','有工作','有自己的房子','信贷情况']\n",
    "featLabels=[]\n",
    "myTree=createTree(dataSet,labels,featLabels)\n",
    "print(myTree)\n",
    "\n",
    "#测试数据\n",
    "testVec=[0,1]\n",
    "result=predict(myTree,featLabels,testVec)\n",
    "if result:\n",
    "    print('放贷')\n",
    "else:\n",
    "    print('不放贷')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/decision_tree_classifier.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
