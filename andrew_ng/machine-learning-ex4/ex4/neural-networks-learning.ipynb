{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1), (401, 25), (26, 10))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "data_mat = scipy.io.loadmat('ex4data1.mat')\n",
    "weight_mat = scipy.io.loadmat('ex4weights.mat')\n",
    "data_mat['X'].shape, data_mat['y'].shape, weight_mat['Theta1'].T.shape, weight_mat['Theta2'].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_mat['X']\n",
    "y = data_mat['y']\n",
    "theta1 = weight_mat['Theta1'].T\n",
    "theta2 = weight_mat['Theta2'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_gradient(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "# Feedforward Propagation and Prediction\n",
    "# args: theta need be transposed, theta shape: (L-1层特征值+1， L层特征值)\n",
    "# call: layer(x, theta)\n",
    "# out shape: (m, layer_size), like: a1.shape(5000, 400), a2.shape(5000, 25), a3.shape(5000, 10)\n",
    "def layer_no_zero(x, theta):\n",
    "    m = x.shape[0]\n",
    "    num_labels = theta.shape[0]\n",
    "    layer_input = np.append(np.ones((m, 1)), x, axis=1)\n",
    "    z = np.dot(layer_input, theta)\n",
    "    layer_out = sigmoid(z)\n",
    "    return layer_out\n",
    "\n",
    "# a1.shape(5000, 400), a2.shape(5000, 25), a3.shape(5000, 10)\n",
    "def forward(Theta1, Theta2, X):\n",
    "    a1 = X\n",
    "    a2 = layer_no_zero(a1, Theta1)\n",
    "    a3 = layer_no_zero(a2, Theta2)\n",
    "    return a1, a2, a3\n",
    "\n",
    "# shape(5000, 10)\n",
    "# num_labels 为分类的数字（1-10）\n",
    "def transfer_y(y, num_labels):\n",
    "    m = y.size\n",
    "    I = np.eye(num_labels)\n",
    "    Y = np.zeros((m, num_labels))\n",
    "    for i in np.arange(m):\n",
    "        Y[i, :] = I[y[i][0] - 1, :]\n",
    "    return Y\n",
    "\n",
    "def cost_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_nn):\n",
    "    \n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size*(input_layer_size+1)], (input_layer_size+1, hidden_layer_size), 'C')\n",
    "    Theta2 = np.reshape(nn_params[hidden_layer_size*(input_layer_size+1):], (hidden_layer_size+1, num_labels), 'C')\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    Y = transfer_y(y, num_labels)\n",
    "    a1, a2, h = forward(Theta1, Theta2, X)\n",
    "\n",
    "    regulariz_first_layer = np.sum(np.power(Theta1[1:, :], 2))\n",
    "    regulariz_second_layer = np.sum(np.power(Theta2[1:, :], 2))\n",
    "    regulariz = (lambda_nn/(2*m))*(regulariz_first_layer + regulariz_second_layer)\n",
    "    \n",
    "    # 点乘(*, 对应位置相乘，两个乘数和结果的shape一样)，不是向量(np.dot)乘积\n",
    "    J = (1.0/m) * np.sum((-Y) * np.log(h) - (1-Y) * np.log(1-h))\n",
    "    J = J + regulariz\n",
    "    return J\n",
    "\n",
    "# a_1 = (5000, 401)\n",
    "# a_2 = (5000, 26)\n",
    "# a_3 = (5000, 10)\n",
    "# theta_1 = (401, 25)\n",
    "# theta_2 = (26, 10)\n",
    "# d_1 = (401, 25)\n",
    "# d_2 = (26, 10)\n",
    "# d_3 = (5000, 10)\n",
    "def grad_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_nn):\n",
    "    \n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size*(input_layer_size+1)], (input_layer_size+1, hidden_layer_size), 'C')\n",
    "    Theta2 = np.reshape(nn_params[hidden_layer_size*(input_layer_size+1):], (hidden_layer_size+1, num_labels), 'C')\n",
    "    \n",
    "    # a1.shape(5000, 400), a2.shape(5000, 25), a3.shape(5000, 10)\n",
    "    a1, a2, a3 = forward(Theta1, Theta2, X)\n",
    "    a1_full = np.append(np.ones((a1.shape[0], 1)), a1, axis=1)\n",
    "    a2_full = np.append(np.ones((a2.shape[0], 1)), a2, axis=1)\n",
    "    \n",
    "    # Delta3.shape(5000, 10)\n",
    "    Y = transfer_y(y, num_labels)\n",
    "    Delta3 = a3 - Y\n",
    "    # Delta2.shape(26, 10) = a2_full.T.shape(26, 5000) * d3.shape(5000, 10)\n",
    "    Delta2 = np.dot(a2_full.T, Delta3)\n",
    "    # d2.shape(5000, 25) = (5000, 10) * (26-1, 10).T .* (5000, 25) .* (5000, 25)\n",
    "    d2 = np.dot(Delta3, Theta2[1:, :].T) * a2 * (1-a2)\n",
    "    # Delta1.shape(401, 25) = a1_full.T.shape(401, 5000) * d2.shape(5000, 25)\n",
    "    Delta1 = np.dot(a1_full.T, d2)\n",
    "    \n",
    "    Theta2_new = 1/m * Delta2 + np.append(np.zeros((1, Theta2.shape[1])), lambda_nn/m * Theta2[1:, :], axis=0)\n",
    "    Theta1_new = 1/m * Delta1 + np.append(np.zeros((1, Theta1.shape[1])), lambda_nn/m * Theta1[1:, :], axis=0)\n",
    "        \n",
    "    return np.append(Theta1_new.flatten(), Theta2_new.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38376985909092365"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "nn_params = np.append(theta1.flatten(), theta2.flatten())\n",
    "cost_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10285,)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "nn_params = np.append(theta1.flatten(), theta2.flatten())\n",
    "Theta_new = grad_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, 1)\n",
    "Theta_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.301214620603095\n",
       "     jac: array([-3.65227123e-06,  8.98240852e-07, -5.59367396e-06, ...,\n",
       "       -9.19724902e-08,  9.38889915e-07, -3.39321657e-07])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 6520\n",
       "     nit: 2693\n",
       "    njev: 6520\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 1.22650776, -2.17616782,  1.91865553, ..., -2.67391977,\n",
       "       -2.70700525, -2.09755106])"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.optimize as op\n",
    "\n",
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "nn_params = np.append(theta1.flatten(), theta2.flatten())\n",
    "# x0 must be（n,0）\n",
    "result_reg = op.minimize(fun = cost_function, x0 = nn_params, args = (input_layer_size, hidden_layer_size, num_labels, X, y, 1), method = 'CG', jac = grad_function)\n",
    "\n",
    "nn_theta_reg = result_reg.x\n",
    "result_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.68"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for scipy.optimize\n",
    "\n",
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "Theta1_final_nn = np.reshape(nn_theta_reg[:hidden_layer_size*(input_layer_size+1)], (input_layer_size+1, hidden_layer_size), 'C')\n",
    "Theta2_final_nn = np.reshape(nn_theta_reg[hidden_layer_size*(input_layer_size+1):], (hidden_layer_size+1, num_labels), 'C')\n",
    "\n",
    "a1, a2, a3 = forward(Theta1_final_nn, Theta2_final_nn, X)\n",
    "pred = np.argmax(a3, axis = 1) + 1\n",
    "np.mean(pred == y.flatten()) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for loop to decrease grad\n",
    "# https://github.com/Benlau93/Machine-Learning-by-Andrew-Ng-in-Python/tree/master/LogisticRegression\n",
    "\n",
    "def gradientDescentnn(X,y,initial_nn_params,alpha,num_iters,Lambda,input_layer_size, hidden_layer_size, num_labels):\n",
    "    \n",
    "    Theta1 = np.reshape(initial_nn_params[:hidden_layer_size*(input_layer_size+1)], (input_layer_size+1, hidden_layer_size), 'C')\n",
    "    Theta2 = np.reshape(initial_nn_params[hidden_layer_size*(input_layer_size+1):], (hidden_layer_size+1, num_labels), 'C')\n",
    "    \n",
    "    J_history =[]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        nn_params = np.append(Theta1.flatten(),Theta2.flatten())\n",
    "        cost = cost_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, 1)\n",
    "        grad = grad_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, transfer_y(y, num_labels), 0)\n",
    "        \n",
    "        grad1 = np.reshape(grad[:hidden_layer_size*(input_layer_size+1)], (input_layer_size+1, hidden_layer_size), 'C')\n",
    "        grad2 = np.reshape(grad[hidden_layer_size*(input_layer_size+1):], (hidden_layer_size+1, num_labels), 'C')\n",
    "    \n",
    "        Theta1 = Theta1 - (alpha * grad1)\n",
    "        Theta2 = Theta2 - (alpha * grad2)\n",
    "        J_history.append(cost)\n",
    "    \n",
    "    nn_paramsFinal = np.append(Theta1.flatten(),Theta2.flatten())\n",
    "    return nn_paramsFinal , J_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7534771457290492,\n",
       " 0.7522031518744885,\n",
       " 0.7509379228342219,\n",
       " 0.7496813739301598,\n",
       " 0.7484334213570907]"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def randInitializeWeights(L_in, L_out):\n",
    "    epsilon = 0.12\n",
    "    return np.random.rand(L_in+1, L_out) * 2 * epsilon - epsilon\n",
    "\n",
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "initial_theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
    "initial_theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
    "initial_nn_params = np.append(initial_theta1.flatten(), initial_theta2.flatten())\n",
    "nn_paramsFinal, nnJ_history = gradientDescentnn(X,y,initial_nn_params,0.8,300,1,input_layer_size, hidden_layer_size, num_labels)\n",
    "\n",
    "# Theta1_final = np.reshape(nn_paramsFinal[:hidden_layer_size*(input_layer_size+1)], (input_layer_size+1, hidden_layer_size), 'C')\n",
    "# Theta2_final = np.reshape(nn_paramsFinal[hidden_layer_size*(input_layer_size+1):], (hidden_layer_size+1, num_labels), 'C')\n",
    "nnJ_history[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.61999999999999"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for loop\n",
    "a1, a2, a3 = forward(Theta1_final, Theta2_final, X)\n",
    "pred = np.argmax(a3, axis = 1) + 1\n",
    "np.mean(pred == y.flatten()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
